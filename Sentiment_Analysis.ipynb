{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " #### Setting up Apache Spark"
      ],
      "metadata": {
        "id": "suFAo3De08BI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fBIf77LLJqU-"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import string\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"spark-3.2.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "ouPlthhzJ7_H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "metadata": {
        "id": "sPvtR3wVJ-t-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ffc30bc-b507-488f-e326-beed6746cf81"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'spark-3.2.0-bin-hadoop3.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initializing the SparkSession"
      ],
      "metadata": {
        "id": "ANUvn4lm0pHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "metadata": {
        "id": "CAR3UkJgKBV9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "1353552b-557e-4e72-ff71-285c2c07a441"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5aa7b3af2161:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google Drive Mounting on Colab"
      ],
      "metadata": {
        "id": "V6y54DGJ1K6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zy39IqEgKG6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9c8113-8168-41af-e211-e9366f41b329"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading the dataset and extracting the filenames into a list"
      ],
      "metadata": {
        "id": "pOuhDU2_zv-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Analysis/data_moviereviews'\n",
        "files = sc.wholeTextFiles(data_path)\n",
        "filename_list = files.map(lambda x: x[0].split('/')[-1]).collect()\n",
        "print(filename_list[:10])"
      ],
      "metadata": {
        "id": "FAHW9i_xeb5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0df30a-ceab-421c-9d67-773165892b40"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cv500_10251.txt', 'cv500_10722.txt', 'cv501_11657.txt', 'cv501_12675.txt', 'cv502_10406.txt', 'cv502_10970.txt', 'cv503_10558.txt', 'cv503_11196.txt', 'cv504_29120.txt', 'cv505_12090.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing of the Movie Reviews data"
      ],
      "metadata": {
        "id": "iIWhSTuJojOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Remove punctuation and extra spaces from review\n",
        "    cleaned_text = text.translate(str.maketrans('', '', string.punctuation)).replace('\\n', ' ')\n",
        "    words = cleaned_text.split()\n",
        "    return words\n",
        "\n",
        "preprocessed_data = files.map(lambda x: (x[0].split('/')[-1], preprocess_text(x[1])))\n",
        "data_df = preprocessed_data.toDF([\"Filename\", \"Review\"])\n",
        "data_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgFW4Lxqp-sg",
        "outputId": "c288e5e0-57fd-4b6e-9cbc-601967ece755"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------------+\n",
            "|       Filename|              Review|\n",
            "+---------------+--------------------+\n",
            "|cv500_10251.txt|[losing, a, job, ...|\n",
            "|cv500_10722.txt|[you, always, hav...|\n",
            "|cv501_11657.txt|[as, much, as, i,...|\n",
            "|cv501_12675.txt|[synopsis, easily...|\n",
            "|cv502_10406.txt|[the, postman, de...|\n",
            "|cv502_10970.txt|[the, blues, brot...|\n",
            "|cv503_10558.txt|[there, are, cert...|\n",
            "|cv503_11196.txt|[michael, crichto...|\n",
            "|cv504_29120.txt|[american, pie, 2...|\n",
            "|cv505_12090.txt|[some, critics, i...|\n",
            "|cv504_29243.txt|[i, guess, its, a...|\n",
            "|cv505_12926.txt|[well, what, are,...|\n",
            "|cv506_15956.txt|[much, ballyhoo, ...|\n",
            "|cv506_17521.txt|[this, film, is, ...|\n",
            "| cv507_9220.txt|[capsule, sidespl...|\n",
            "|cv508_16006.txt|[maybe, the, most...|\n",
            "| cv507_9509.txt|[midway, through,...|\n",
            "|cv509_15888.txt|[as, i, write, th...|\n",
            "|cv508_17742.txt|[if, the, 70s, no...|\n",
            "|cv509_17354.txt|[synopsis, nice, ...|\n",
            "+---------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_RDD = data_df.select('Review').rdd.flatMap(list)"
      ],
      "metadata": {
        "id": "AdC1TZQtiRN1"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading Positive words into RDD"
      ],
      "metadata": {
        "id": "rOTU5rrBx83p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_rdd = spark.sparkContext.textFile('/content/drive/MyDrive/Analysis/pos.txt')\n",
        "pos_words = pos_rdd.collect()  # Collect the RDD into a Python list\n",
        "print(pos_words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MClCo3AlyjOx",
        "outputId": "a13e3347-8124-469d-8e78-8a5b27546068"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation', 'accolade']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Counting of Positive words in Reviews"
      ],
      "metadata": {
        "id": "eIj1oB4AvhdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_word_counts = review_RDD.map(lambda review: len([word for word in review if word in pos_words]))\n",
        "pos_word_counts_list = pos_word_counts.collect()\n",
        "pos_word_counts.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKDSdudytSwX",
        "outputId": "00529e29-37c6-4c12-e7b4-5e1471ce61a2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29, 21, 71, 26, 20, 25, 60, 15, 13, 44]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading Negative words into RDD"
      ],
      "metadata": {
        "id": "IduQa91KzHU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_rdd = spark.sparkContext.textFile('/content/drive/MyDrive/Analysis/neg.txt')\n",
        "neg_words = neg_rdd.collect()\n",
        "print(neg_words[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0DVA74DzHlX",
        "outputId": "4fe24b16-c603-43bb-8249-0b970718ae3a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted', 'aborts', 'abrade']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Counting of Negative words in Reviews"
      ],
      "metadata": {
        "id": "UXMN8Y8Yvoef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_word_counts = review_RDD.map(lambda review: len([word for word in review if word in neg_words]))\n",
        "neg_word_counts_list = neg_word_counts.collect()\n",
        "neg_word_counts.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B51WNdDiYGy",
        "outputId": "51d8f7ae-a2ee-4180-b0a7-a83c7bba9c8c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[35, 17, 73, 42, 33, 27, 34, 12, 17, 82]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assigning sentiment based on maximum count of positive/negative count"
      ],
      "metadata": {
        "id": "Ke9ASgquvvMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_list = list(map(lambda pos, neg: 'positive' if pos > neg else 'negative', pos_word_counts_list, neg_word_counts_list))\n",
        "print(sentiment_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT94XRvOiqTJ",
        "outputId": "c9e5f364-fd98-4a19-c530-e20923084b7e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['filename','positive_count','negative_count','sentiment']\n",
        "df = spark.createDataFrame(zip(filename_list,pos_word_counts_list,neg_word_counts_list,sentiment_list), columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pirgbrGzixZP",
        "outputId": "ffb5f25f-2ed0-4143-cbe4-7e59cd78f06d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+--------------+---------+\n",
            "|       filename|positive_count|negative_count|sentiment|\n",
            "+---------------+--------------+--------------+---------+\n",
            "|cv500_10251.txt|            29|            35| negative|\n",
            "|cv500_10722.txt|            21|            17| positive|\n",
            "|cv501_11657.txt|            71|            73| negative|\n",
            "|cv501_12675.txt|            26|            42| negative|\n",
            "|cv502_10406.txt|            20|            33| negative|\n",
            "|cv502_10970.txt|            25|            27| negative|\n",
            "|cv503_10558.txt|            60|            34| positive|\n",
            "|cv503_11196.txt|            15|            12| positive|\n",
            "|cv504_29120.txt|            13|            17| negative|\n",
            "|cv505_12090.txt|            44|            82| negative|\n",
            "|cv504_29243.txt|            28|            26| positive|\n",
            "|cv505_12926.txt|            21|            29| negative|\n",
            "|cv506_15956.txt|            66|            54| positive|\n",
            "|cv506_17521.txt|             1|             2| negative|\n",
            "| cv507_9220.txt|            22|            38| negative|\n",
            "|cv508_16006.txt|            68|            50| positive|\n",
            "| cv507_9509.txt|            23|            35| negative|\n",
            "|cv509_15888.txt|            92|            20| positive|\n",
            "|cv508_17742.txt|             8|            12| negative|\n",
            "|cv509_17354.txt|            23|            10| positive|\n",
            "+---------------+--------------+--------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}